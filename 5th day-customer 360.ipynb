{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2d7b3f9-4cb9-4e19-b7ac-183fb9dd89a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json, to_timestamp, when, lit\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "\n",
    "cosmos_endpoint = dbutils.secrets.get(\"kv\", \"COSMOS_ENDPOINT\")\n",
    "cosmos_masterkey = dbutils.secrets.get(\"kv\", \"COSMOS_KEY\")\n",
    "cosmos_database = \"BankDB\"\n",
    "cosmos_container = \"Transactions\"  \n",
    "\n",
    "\n",
    "cosmos_cfg = {\n",
    "  \"spark.cosmos.accountEndpoint\": cosmos_endpoint,\n",
    "  \"spark.cosmos.accountKey\": cosmos_masterkey,\n",
    "  \"spark.cosmos.database\": cosmos_database,\n",
    "  \"spark.cosmos.container\": cosmos_container,\n",
    "  \"spark.cosmos.read.inferSchema.enabled\": \"true\"\n",
    "}\n",
    "\n",
    "df = spark.read.format(\"cosmos.oltp\").options(**cosmos_cfg).load()\n",
    "\n",
    "\n",
    "df_clean = (df\n",
    "            .withColumn(\"TransactionTimestamp\", to_timestamp(col(\"TransactionTime\")))\n",
    "            .withColumn(\"Amount\", col(\"TransactionAmount\").cast(\"double\"))\n",
    "            .filter(col(\"Amount\").isNotNull())\n",
    "           )\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import sum as _sum, avg as _avg, count as _count, month\n",
    "\n",
    "agg = (df_clean.groupBy(\"CustomerID\")\n",
    "       .agg(_sum(\"Amount\").alias(\"TotalSpent\"),\n",
    "            _avg(\"Amount\").alias(\"AvgTxnAmount\"),\n",
    "            _count(\"*\").alias(\"TxnCount\"))\n",
    "      )\n",
    "\n",
    "\n",
    "jdbc_url = dbutils.secrets.get(\"kv\", \"SYNAPSE_JDBC_URL\")\n",
    "jdbc_user = dbutils.secrets.get(\"kv\", \"SYNAPSE_USER\")\n",
    "jdbc_pass = dbutils.secrets.get(\"kv\", \"SYNAPSE_PASSWORD\")\n",
    "\n",
    "synapse_table = \"dbo.Customer360_Fact\"\n",
    "\n",
    "agg.write \\\n",
    "   .format(\"com.databricks.spark.sqldw\") \\\n",
    "   .option(\"url\", jdbc_url) \\\n",
    "   .option(\"user\", jdbc_user) \\\n",
    "   .option(\"password\", jdbc_pass) \\\n",
    "   .option(\"dbtable\", synapse_table) \\\n",
    "   .option(\"forward_spark_azure_storage_credentials\", \"true\") \\\n",
    "   .option(\"tempdir\", \"wasbs://<container>@<storage>.blob.core.windows.net/tempdir\") \\\n",
    "   .mode(\"overwrite\") \\\n",
    "   .save()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "customer 360",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}